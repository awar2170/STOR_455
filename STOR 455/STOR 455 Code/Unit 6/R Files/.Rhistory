Exams4 <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/Exams4.csv")
Diet <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/Diet.csv")
Glue <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/Glue.csv")
head(Diet)
amodA = aov(Grade~factor(Exam), data=Exams4)
summary(amodA)
amodB = aov(Grade~Student, data=Exams4)
summary(amodB)
amodC = aov(Grade~factor(Exam)+Student, data=Exams4)
summary(amodC)
TukeyHSD(amodC)
par(mar=c(4,7,3,1))
hsd=TukeyHSD(amodC)
plot(hsd,las=2)
par(mar=c(5,4,2,2))
Glue_model = aov(Force ~ Thickness + Type + Thickness*Type, data=Glue)
summary(Glue_model)
TukeyHSD(Glue_model)
interaction.plot(Glue$Type, Glue$Thickness, Glue$Force)
interaction.plot(Glue$Thickness, Glue$Type, Glue$Force)
round(tapply(Exams4$Grade,Exams4$Student,sd),2)
boxplot(Grade ~ Exam, data = Exams4)
library(readr)
Exams4 <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/Exams4.csv")
Diet <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/Diet.csv")
Glue <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/Glue.csv")
library(readr)
Exams4 <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/Exams4.csv")
Diet <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/Diet.csv")
Glue <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/Glue.csv")
head(Diet)
Diet$weightchange = Diet$Preweight - Diet$weight6weeks
weightchange_diet = aov(weightchange~factor(Diet), data = Diet)
summary(weightchange_diet)
plot(weightchange_diet, 1:2)
TukeyHSD(weightchange_diet)
tapply(Diet$weightchange, Diet$Diet, mean)
weightchange_Sex <- aov(weightchange~factor(Sex), data = Diet)
summary(weightchange_Sex)
plot(weightchange_Sex, 1:2)
plot(amodC, 1:2)
library(readr)
Exams4 <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/Exams4.csv")
Diet <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/Diet.csv")
Glue <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/Glue.csv")
head(Diet)
Diet$weightchange = Diet$Preweight - Diet$weight6weeks
weightchange_diet = aov(weightchange~factor(Diet), data = Diet)
summary(weightchange_diet)
plot(weightchange_diet, 1:2)
TukeyHSD(weightchange_diet)
tapply(Diet$weightchange, Diet$Diet, mean)
weightchange_Sex <- aov(weightchange~factor(Sex), data = Diet)
summary(weightchange_Sex)
plot(weightchange_Sex, 1:2)
amodA = aov(Grade~factor(Exam), data=Exams4)
summary(amodA) #This SSR Residuals is bigger because there is alot that is not being explained by the predictor
amodB = aov(Grade~Student, data=Exams4)
summary(amodB) #This SSR Res id smaller bc when we look at mean by student, a lot of the variability is explained; when we predict Bub's score with the other average that he did, we know more where it is coming from
#amodC = combines amodA and amodB
amodC = aov(Grade~factor(Exam)+Student, data=Exams4)
summary(amodC)
TukeyHSD(amodC)
par(mar=c(4,7,3,1))
hsd=TukeyHSD(amodC)
plot(hsd,las=2)
par(mar=c(5,4,2,2))
plot(amodC, 1:2)
weightchange_both <- aov(weightchange~factor(Diet)+factor(Sex), data = Diet)
summary(weightchange_both)
plot(weightchange_both, 1:2)
TukeyHSD(weightchange_diet)
library(readr)
Diet <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/Diet.csv")
Glue <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/Glue.csv")
Pulse <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/Pulse.csv")
# Want to try and predict the force requried to pull these things apart by the thickness and type of glue in the data and also that interaction
Glue_model = aov(Force ~ Thickness + Type + Thickness*Type, data=Glue)
summary(Glue_model)
# This gives more information than we wanted because it gives the first line as a test by thickness
interaction.plot(Glue$Type, Glue$Thickness, Glue$Force)
interaction.plot(Glue$Thickness, Glue$Type, Glue$Force)
knitr::opts_chunk$set(echo = TRUE,warning=F)
options(scipen=999)
library(tidyverse)
library(modelr)
library(broom)
bgg<-read.csv("bgg.csv")
bgg2=bgg[,c(4:13,15:20)]
head(bgg2)
head(bgg2)
names(bbg2)
head(bgg2)
names(bgg2)
head(bgg2)
bgg3$duration <- 2018-bgg2$year+1
bgg3 <- bgg2
bgg3$duration <- 2018-bgg2$year+1
mutate(bgg, duration=2018-year+1, vote.per.year=num_votes/duration, own.per.year=owned/duration, player.range=max_players-min_players, log_vote=log(num_votes+1), log_own=log(owned+1), diff_rating=avg_rating-geek_rating)
head(bgg3)
bgg3 <- mutate(bgg, duration=2018-year+1, vote.per.year=num_votes/duration, own.per.year=owned/duration, player.range=max_players-min_players, log_vote=log(num_votes+1), log_own=log(owned+1), diff_rating=avg_rating-geek_rating)
head(bgg3)
names(bgg3)
names(bgg3)
head(bgg3$vote.per.year)
head(bgg3$log_vote)
head(bgg3)
plot(bgg3$geek_rating)
plot(bgg3$geek_rating, bgg3$num_votes
plot(bgg3$geek_rating, bgg3$num_votes)
plot(bgg3$num_votes)
ggplot(bgg3, aes(x=num_votes, y=geek_rating)) + geom_point()
ggplot(bgg3, aes(x=num_votes, y=geek_rating)) + geom_point()
ggplot(bgg3, aes(x=owned, y=geek_rating)) + geom_point()
ggplot(bgg3, aes(x=log_vote, y=geek_rating)) + geom_point()
ggplot(bgg3, aes(x=log_own, y=geek_rating)) + geom_point()
set.seed(COMPLETE)
sample(bgg3, replace = FALSE, prob = .8)
sample(bgg3, nrow(bgg3) replace = FALSE, prob = .8)
sample(bgg3, nrow(bgg3), replace = FALSE, prob = .8)
sample(bgg3, nrow(bgg3), prob = .8)
sample(bgg3, nrow(bgg3))
sample(bgg3, 20)
str(bgg3)
4999*.8
4999*.8
bgg4= bgg3 %>%
mutate(Set=sample(bgg3, 3998))
sample(1:length(bgg3), .8)
sample(1:length(bgg3), 1)
sample(1:length(bgg3), 3998)
sample(1:nrow(bgg3), 3998)
set.seed(320)
# We got 3998 by multiplying the total number of rows of bgg3 by 0.8.
bgg4= bgg3 %>%
mutate(Set=sample(1:nrow(bgg3), 3998))
set.seed(320)
# We got 3998 by multiplying the total number of rows of bgg3 by 0.8.
bgg4= bgg3 %>%
mutate(Set=sample(1:nrow(bgg3), 1))
train.bgg<-filter(bgg4,Set=="Train")
test.bgg<-filter(bgg4,Set=="Test")
set.seed(320)
# We got 3998 by multiplying the total number of rows of bgg3 by 0.8.
bgg4= bgg3 %>%
mutate(Set=sample(1:nrow(bgg3), 3998))
bgg4= bgg3 %>%
mutate(Set=sample(1:nrow(bgg3), 1))
head(bgg4)
nrow(bgg4)
mutate(Set=sample(c(train.bgg, test.bgg), prob = c(0.8, 0.2))
set.seed(320)
set.seed(320)
# We got 3998 by multiplying the total number of rows of bgg3 by 0.8.
#Sample(What we are creating(test and train dataset), probabilities )
bgg4= bgg3 %>%
mutate(Set=sample(c("train", "test"), size = nrow(bgg3), prob = c(0.8, 0.2), replace = TRUE)
train.bgg<-filter(bgg4,Set=="Train")
set.seed(320)
# We got 3998 by multiplying the total number of rows of bgg3 by 0.8.
#Sample(What we are creating(test and train dataset), probabilities )
bgg4= bgg3 %>%
mutate(Set=sample(c("train", "test"), size = nrow(bgg3), prob = c(0.8, 0.2), replace = TRUE))
train.bgg<-filter(bgg4,Set=="Train")
test.bgg<-filter(bgg4,Set=="Test")
set.seed(320)
# We got 3998 by multiplying the total number of rows of bgg3 by 0.8.
#Sample(What we are creating(test and train dataset), probabilities )
bgg4= bgg3 %>%
mutate(Set=sample(c("Train", "Test"), size = nrow(bgg3), prob = c(0.8, 0.2), replace = TRUE))
train.bgg<-filter(bgg4,Set=="Train")
test.bgg<-filter(bgg4,Set=="Test")
lm1 = lm(greek_rating~log(num_votes),data=train.bgg)
lm1 = lm(geek_rating~log(num_votes),data=train.bgg)
lm1 = lm(geek_rating~log(num_votes),data=train.bgg)
lm2 = lm(geek_rating~log(owned),data=train.bgg)
lm3 = lm(geek_rating~log(owned)+vote.per.year+weight,data=train.bgg)
knitr::opts_chunk$set(echo = TRUE,warning=F)
options(scipen=999)
library(tidyverse)
library(modelr)
library(broom)
bgg<-read.csv("bgg.csv")
bgg2=bgg[,c(4:13,15:20)]
head(bgg2)
names(bgg2)
bgg3 <- mutate(bgg, duration=2018-year+1, vote.per.year=num_votes/duration, own.per.year=owned/duration, player.range=max_players-min_players, log_vote=log(num_votes+1), log_own=log(owned+1), diff_rating=avg_rating-geek_rating)
head(bgg3)
ggplot(bgg3, aes(x=num_votes, y=geek_rating)) + geom_point()
ggplot(bgg3, aes(x=owned, y=geek_rating)) + geom_point()
ggplot(bgg3, aes(x=log_vote, y=geek_rating)) + geom_point()
ggplot(bgg3, aes(x=log_own, y=geek_rating)) + geom_point()
set.seed(320)
#Sample(What we are creating(test and train dataset), probabilities )
bgg4= bgg3 %>%
mutate(Set=sample(c("Train", "Test"), size = nrow(bgg3), prob = c(0.8, 0.2), replace = TRUE))
train.bgg<-filter(bgg4,Set=="Train")
test.bgg<-filter(bgg4,Set=="Test")
lm1 = lm(geek_rating~log(num_votes),data=train.bgg)
lm2 = lm(geek_rating~log(owned),data=train.bgg)
lm3 = lm(geek_rating~log(owned)+vote.per.year+weight,data=train.bgg)
lm1
lm1$residuals
test.bgg2 <- rbind(lm1$residuals, lm2$residuals, lm3$residuals)
lm1 = lm(geek_rating~log(num_votes),data=train.bgg)
lm
lm1
lm1.pred = predict.lm(lm1, test.bgg)
lm1.res = test.bgg$geek_rating - lm1.pred
lm2.pred = predict.lm(lm2, test.bgg)
lm2.res = test.bgg$geek_rating - lm2.pred
lm3.pred = predict.lm(lm3, test.bgg)
lm3.res = test.bgg$geek_rating - lm3.pred
test.bgg2 <- data.frame(lm1.pred,lm1.res,lm2.pred,lm2.res,lm3.pred,lm3.res)
str(test.bgg2)
MAE.func(test)
test=c(-5,-2,0,3,5)
MAE.func <- function(residuals){
MAE <- mean(abs(residuals))
return(MAE)
}
MAE.func(test)
test=c(-5,-2,0,3,5)
MAE.func <- function(x){
MAE <- mean(abs(x))
return(MAE)
}
MAE.func(test)
test=c(-5,-2,0,3,5)
MAE.func <- function(residuals){
MAE <- mean(abs(residuals))
return(MAE)
}
MAE.func(test)
MAE.func(lm1.res)
MAE.func(lm2.res)
MAE.func(lm3.res)
library(readr)
StateSAT <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/StateSAT.csv")
Pulse <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/Pulse.csv")
modSAT2ndorder=lm(SAT~Takers+Expend+I(Takers^2)+I(Expend^2)+I(Takers*Expend),data=StateSAT)
summary(modSAT2ndorder)
modSAT2ndorder_Reduced=lm(SAT~Takers+Expend+I(Takers^2)+I(Expend^2),data=StateSAT)
anova(modSAT2ndorder_Reduced, modSAT2ndorder)
modSAT2ndorder_Reduced2=lm(SAT~Takers+Expend, data=StateSAT)
anova(modSAT2ndorder_Reduced2,modSAT2ndorder)
modSAT2ndorder_Reduced3 = lm(SAT~Takers+I(Takers^2),data=StateSAT)
anova(modSAT2ndorder_Reduced3, modSAT2ndorder)
set.seed(12345)
rows <- sample(nrow(Pulse))
Pulse_shuffled = Pulse[rows,]
PulseTrain=Pulse_shuffled[1:300,]
PulseHoldout=Pulse_shuffled[301:375,]
#"best" model
PulseTrainMod=lm(Active~Rest+Sex+Hgt+Wgt,data=PulseTrain)
summary(PulseTrainMod)
plot(PulseTrainMod)
#predict active heart rates for data in the holdout sample with the model made from the training data
fitActive=predict(PulseTrainMod,newdata=PulseHoldout)
#Actual active heart rates in holdout sample minus their predicted values
holdoutresid=PulseHoldout$Active - fitActive
#Center, spread, and shape for the distribution of holdouts
mean(holdoutresid)
sd(holdoutresid)
qqnorm(holdoutresid)
qqline(holdoutresid)
cor(PulseHoldout$Active,fitActive)
#Correlation between predicted and actual active heart rates
crosscorr=cor(PulseHoldout$Active,fitActive)
crosscorr^2
#Change in r^2 from the training to the holdout
shrinkage = summary(PulseTrainMod)$r.squared-crosscorr^2
shrinkage
library(readr)
library(leaps)
StateSAT <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/StateSAT.csv")
source("https://raw.githubusercontent.com/JA-McLean/STOR455/master/scripts/ShowSubsets.R")
mod = lm(SAT~Years+Expend+Rank, data=StateSAT)
summary(mod)
plot(mod)
plot(SAT~., data=StateSAT[2:8])
modSAT1 = lm(SAT~Takers, data=StateSAT)
summary(modSAT1)
plot(modSAT1)
modSAT2 = lm(SAT~I(Takers^2), data=StateSAT)
summary(modSAT2)
plot(modSAT2)
StateSAT$TakersSq = StateSAT$Takers^2
modSATquad1 = lm(SAT~Takers + TakersSq, data=StateSAT)
summary(modSATquad1)
plot(modSATquad1)
modSATquad2 = lm(SAT~ Takers+ I(Takers^2), data=StateSAT)
summary(modSATquad2)
modSATquad3 = lm(SAT~poly(Takers, degree=2, raw=TRUE), data=StateSAT)
summary(modSATquad3)
anova(modSATquad3)
plot(SAT~Takers, data=StateSAT)
B0_modSATquad2 = summary(modSATquad2)$coef[1,1]
B1_modSATquad2 = summary(modSATquad2)$coef[2,1]
B2_modSATquad2 = summary(modSATquad2)$coef[3,1]
curve(B0_modSATquad2 + B1_modSATquad2*x + B2_modSATquad2*x^2, add=TRUE)
modSATcubic = lm(SAT~ Takers+ I(Takers^2) + I(Takers^3), data=StateSAT)
summary(modSATcubic)
plot(SAT~Takers, data=StateSAT, main="Cubic Model")
B0_modSATcubic = summary(modSATcubic)$coef[1,1]
B1_modSATcubic = summary(modSATcubic)$coef[2,1]
B2_modSATcubic = summary(modSATcubic)$coef[3,1]
B3_modSATcubic = summary(modSATcubic)$coef[4,1]
curve(B0_modSATcubic + B1_modSATcubic*x + B2_modSATcubic*x^2 + B3_modSATcubic*x^3, add=TRUE)
anova(modSATcubic)
car::vif(modSATcubic)
modSATquad4 = lm(SAT~ Rank+ I(Rank^2), data=StateSAT)
summary(modSATquad4)
plot(modSATquad4)
plot(SAT~Rank, data=StateSAT)
B0_modSATquad4 = summary(modSATquad4)$coef[1,1]
B1_modSATquad4 = summary(modSATquad4)$coef[2,1]
B2_modSATquad4 = summary(modSATquad4)$coef[3,1]
curve(B0_modSATquad4 + B1_modSATquad4*x + B2_modSATquad4*x^2, add=TRUE)
plot(SAT~Rank, data=StateSAT)
mod2 = lm(SAT~I(Rank^2), data=StateSAT)
B0_mod2 = summary(mod2)$coef[1,1]
B1_mod2 = summary(mod2)$coef[2,1]
curve(B0_mod2 + B1_mod2*x^2, add=TRUE)
DATA3=na.omit(lm3) %>% crossv_kfold(10)
DATA3=na.omit(MAE.func(lm3)) %>% crossv_kfold(10)
DATA3=na.omit(MAE.func(lm3.res)) %>% crossv_kfold(10)
DATA3=na.omit(MAE.func(lm3.pred)) %>% crossv_kfold(10)
DATA3=na.omit(lm3 %>% crossv_kfold(10)
DATA3
DATA3=na.omit(lm3 %>% crossv_kfold(10))
DATA3
DATA3=na.omit(lm3 %>% crossv_kfold(10))
DATA3=na.omit(lm3 %>% crossv_kfold(10))
DATA3=na.omit(lm3.pred %>% crossv_kfold(10))
DATA3=na.omit(test.bbg %>% crossv_kfold(10))
DATA3=na.omit(test.bgg %>% crossv_kfold(10))
DATA3
MAE.func(DATA3)
DATA3
DATA3=na.omit(bgg3 %>% crossv_kfold(10))
DATA3
DATA3
MAE.func(DATA3)
DATA3=na.omit(test.bgg %>% crossv_kfold(10))
DATA3
anova(DATA3)
anova(lm3)
library(readr)
Diet <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/Diet.csv")
Glue <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/Glue.csv")
Pulse <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/Pulse.csv")
# Want to try and predict the force requried to pull these things apart by the thickness and type of glue in the data and also that interaction
Glue_model = aov(Force ~ Thickness + Type + Thickness*Type, data=Glue)
summary(Glue_model)
# This gives more information than we wanted because it gives the first line as a test by thickness
# When we look at the itneraction, there is a sig level there; the SSQ for this is higher; Factor A and B are not sig on their own, but the interation is
TukeyHSD(Glue_model)
interaction.plot(Glue$Type, Glue$Thickness, Glue$Force)
interaction.plot(Glue$Thickness, Glue$Type, Glue$Force)
names(Diet)
names(Diet)
Diet$weight_change <- Diet$weight6weeks - Diet$Preweight
mod1 <- aov(weight_change +
factor(Diet)+
factor(Sex)+
factor(Diet)*factor(Sex),
data = Diet)
Diet$weight_change <- Diet$weight6weeks - Diet$Preweight
mod1 <- aov(weight_change +
factor(Diet)+
factor(Sex)+
factor(Diet)*factor(Sex),
data = Diet)
Diet$weight_change <- Diet$weight6weeks - Diet$Preweight
mod1 <- aov(weight_change +
factor(Diet)+
factor(Sex)+
factor(Diet)*factor(Sex),
data = Diet)
Diet$weight_change <- Diet$weight6weeks - Diet$Preweight
mod1 <- aov(weight_change ~
factor(Diet)+
factor(Sex)+
factor(Diet)*factor(Sex),
data = Diet)
summary(mod1)
plot(mod1, 1:2)
TukeyHSD(mod1)
interaction.plot(Diet$Sex, Diet$Diet, Diet$weight_change)
modp2 <_ lm(Active~Rest+factor(Exercise), data = Pulse)
modp2 <- lm(Active~Rest+factor(Exercise), data = Pulse)
Exercise1 = subset(Pulse, Pulse$Exercise == 1)
Exercise2 = subset(Pulse, Pulse$Exercise == 2)
Exercise3 = subset(Pulse, Pulse$Exercise == 3)
lme1 = lm(Active ~ Rest, data = Exercise1)
lme2 = lm(Active ~ Rest, data = Exercise2)
lme3 = lm(Active ~ Rest, data = Exercise3)
plot(Active~Rest, data=Pulse)
abline(lme1)
abline(lme2, col='red')
abline(lme3, col='blue')
lme1.log = lm(log(Active) ~ log(Rest), data=Exercise1)
lme2.log = lm(log(Active) ~ log(Rest), data=Exercise2)
lme3.log = lm(log(Active) ~ log(Rest), data=Exercise3)
plot(log(Active) ~ log(Rest), data=Pulse)
abline(lme1.log)
abline(lme2.log, col='red')
abline(lme3.log, col='blue')
anova(modp2log)
library(readr)
Diet <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/Diet.csv")
Glue <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/Glue.csv")
Pulse <- read_csv("https://raw.githubusercontent.com/JA-McLean/STOR455/master/data/Pulse.csv")
# Want to try and predict the force requried to pull these things apart by the thickness and type of glue in the data and also that interaction
Glue_model = aov(Force ~ Thickness + Type + Thickness*Type, data=Glue)
summary(Glue_model)
# This gives more information than we wanted because it gives the first line as a test by thickness
# When we look at the itneraction, there is a sig level there; the SSQ for this is higher; Factor A and B are not sig on their own, but the interation is
TukeyHSD(Glue_model)
interaction.plot(Glue$Type, Glue$Thickness, Glue$Force)
interaction.plot(Glue$Thickness, Glue$Type, Glue$Force)
Diet$weight_change <- Diet$weight6weeks - Diet$Preweight
mod1 <- aov(weight_change ~
factor(Diet)+
factor(Sex)+
factor(Diet)*factor(Sex),
data = Diet)
summary(mod1)
plot(mod1, 1:2)
TukeyHSD(mod1)
interaction.plot(Diet$Sex, Diet$Diet, Diet$weight_change)
mod1 = aov(Force ~ Thickness, data=Glue)
summary(mod1)
mod2 = lm(Force ~ Thickness, data=Glue)
anova(mod2)
summary(mod2)
mod3 = aov(Force ~ Thickness + Type, data=Glue)
summary(mod3)
mod4 = lm(Force ~ Thickness + Type, data=Glue)
anova(mod4)
summary(mod4)
mod5 = aov(Force ~ Thickness + Type + Thickness*Type, data=Glue)
summary(mod5)
mod6 = lm(Force ~ Thickness + Type + Thickness*Type, data=Glue)
anova(mod6)
summary(mod6)
modp2 = lm(Active ~ Rest + factor(Exercise), data=Pulse)
summary(modp2)
anova(modp2)
plot(modp2, 1:2)
modp2 <- lm(Active~Rest+factor(Exercise), data = Pulse)
summary(modp2)
# People who exercise a small amount, we can get rid of the last two lines and it tells us our realtions bt rest and active heart reate follows that intercept and lope
anova(modp2)
# How the active heart rate is adjected by the intercept
# We are assuming that the resting heart rate follows teh same trend as the active, regardless of your exercise level
Exercise1 = subset(Pulse, Pulse$Exercise == 1)
Exercise2 = subset(Pulse, Pulse$Exercise == 2)
Exercise3 = subset(Pulse, Pulse$Exercise == 3)
lme1 = lm(Active ~ Rest, data = Exercise1)
lme2 = lm(Active ~ Rest, data = Exercise2)
lme3 = lm(Active ~ Rest, data = Exercise3)
plot(Active~Rest, data=Pulse)
abline(lme1)
abline(lme2, col='red')
abline(lme3, col='blue')
# When we look at the three lines over the data, we are hoping that these will be similar in slope.  IF they are much different in terms of slope, from a practical standpoint, there may be an interaction between these that we need to investigate.
##Looking at the data, we are trying to see if they are similar enough with their slope, none look drastically different
modp2log = lm(log(Active)~log(Rest) + factor(Exercise), data = Pulse)
anova(modp2log)
plot(modp2log, 1:2)
lme1.log = lm(log(Active) ~ log(Rest), data=Exercise1)
lme2.log = lm(log(Active) ~ log(Rest), data=Exercise2)
lme3.log = lm(log(Active) ~ log(Rest), data=Exercise3)
plot(log(Active) ~ log(Rest), data=Pulse)
abline(lme1.log)
abline(lme2.log, col='red')
abline(lme3.log, col='blue')
# Doesn't show anything idfferent than before
# IT helped with teh conditions, but it doesn't effect the interaction to consider
anova(modp2log)
n=10 # 10 groups, and taking 10 random groups; of 4 groups; and binding them todaya dn making a df;
#Name the data you randomly call
x1 <- rnorm(n)
x2 <- rnorm(n)
x3 <- rnorm(n)
x4 <- rnorm(n)
x = c(rbind(x1, x2, x3, x4))
data <- data.frame(x)
data$group[        1:n    ] = "A"
data$group[(  n + 1):(2*n)] = "B"
data$group[(2*n + 1):(3*n)] = "C"
data$group[(3*n + 1):(4*n)] = "D"
#Lavene test
# Should all have the same sd from population; by chance what the vlav test would look like
leveneTest(data$x, factor(data$group))
n=400 # 400 groups, and taking 10 random groups; of 4 groups; and binding them todaya dn making a df;
#Name the data you randomly call
x1 <- rnorm(n)
x2 <- rnorm(n)
x3 <- rnorm(n)
x4 <- rnorm(n)
x = c(rbind(x1, x2, x3, x4))
data <- data.frame(x)
data$group[        1:n    ] = "A"
data$group[(  n + 1):(2*n)] = "B"
data$group[(2*n + 1):(3*n)] = "C"
data$group[(3*n + 1):(4*n)] = "D"
#Lavene test
# Should all have the same sd from population; by chance what the vlav test would look like
leveneTest(data$x, factor(data$group))
